{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckYNlXlfIpU5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
        "columns = ['id','country','Label','Text']\n",
        "#Full dataset for Train-Test\n",
        "df=pd.read_csv('/content/twitter_training.csv', names=columns)\n",
        "\n",
        "# Print the shape of dataframe\n",
        "print(df.shape)\n",
        "\n",
        "# Print top 5 rows\n",
        "df.head(5)\n",
        "(74682, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5J_BmhoI0ae",
        "outputId": "e2e39583-2a7a-4860-9f7d-8024e98d8652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(74682, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74682, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRIEJlZOJLyd",
        "outputId": "3c09cabb-0c2c-4d38-c235-2ba70fed5715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74682 entries, 0 to 74681\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   id       74682 non-null  int64 \n",
            " 1   country  74682 non-null  object\n",
            " 2   Label    74682 non-null  object\n",
            " 3   Text     73996 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 2.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of Emotion\n",
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez3CkN9kJQgm",
        "outputId": "4937cb0d-e04d-4ac4-f1af-f9a1bc919201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "Negative      22542\n",
              "Positive      20832\n",
              "Neutral       18318\n",
              "Irrelevant    12990\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s# Show sample\n",
        "for i in range(5):\n",
        "    print(f\"{i+1}: {df['Text'][i]} -> {df['Label'][i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNRN91ymJdep",
        "outputId": "10ceb93a-52d6-4f80-ceb8-b3c3810ba3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: im getting on borderlands and i will murder you all , -> Positive\n",
            "2: I am coming to the borders and I will kill you all, -> Positive\n",
            "3: im getting on borderlands and i will kill you all, -> Positive\n",
            "4: im coming on borderlands and i will murder you all, -> Positive\n",
            "5: im getting on borderlands 2 and i will murder you me all, -> Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "_Op-yd6lJho6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load english language model and create nlp object from it\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "yRSc0sR7Jk10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use this utility function to get the preprocessed text data\n",
        "def preprocess(text):\n",
        "    # remove stop words and lemmatize the text\n",
        "    doc = nlp(text)\n",
        "    filtered_tokens = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        filtered_tokens.append(token.lemma_)\n",
        "\n",
        "    return \" \".join(filtered_tokens)"
      ],
      "metadata": {
        "id": "SMW4kwMuJp43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply the preprocessing function to the 'Text' column\n",
        "df['Preprocessed Text'] = df['Text'].apply(preprocess)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGfxnf-LJT-j",
        "outputId": "8b4f416e-bf8f-40c5-ccca-2ba7d3cb9f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id      country     Label  \\\n",
            "0      2401  Borderlands  Positive   \n",
            "1      2401  Borderlands  Positive   \n",
            "2      2401  Borderlands  Positive   \n",
            "3      2401  Borderlands  Positive   \n",
            "4      2401  Borderlands  Positive   \n",
            "...     ...          ...       ...   \n",
            "74677  9200       Nvidia  Positive   \n",
            "74678  9200       Nvidia  Positive   \n",
            "74679  9200       Nvidia  Positive   \n",
            "74680  9200       Nvidia  Positive   \n",
            "74681  9200       Nvidia  Positive   \n",
            "\n",
            "                                                    Text  \\\n",
            "0      im getting on borderlands and i will murder yo...   \n",
            "1      I am coming to the borders and I will kill you...   \n",
            "2      im getting on borderlands and i will kill you ...   \n",
            "3      im coming on borderlands and i will murder you...   \n",
            "4      im getting on borderlands 2 and i will murder ...   \n",
            "...                                                  ...   \n",
            "74677  Just realized that the Windows partition of my...   \n",
            "74678  Just realized that my Mac window partition is ...   \n",
            "74679  Just realized the windows partition of my Mac ...   \n",
            "74680  Just realized between the windows partition of...   \n",
            "74681  Just like the windows partition of my Mac is l...   \n",
            "\n",
            "                                       Preprocessed Text  \n",
            "0                                m get borderland murder  \n",
            "1                                       come border kill  \n",
            "2                                  m get borderland kill  \n",
            "3                               m come borderland murder  \n",
            "4                              m get borderland 2 murder  \n",
            "...                                                  ...  \n",
            "74677  realize Windows partition Mac like 6 year Nvid...  \n",
            "74678  realize Mac window partition 6 year Nvidia dri...  \n",
            "74679  realize window partition Mac 6 year Nvidia dri...  \n",
            "74680  realize window partition Mac like 6 year Nvidi...  \n",
            "74681  like window partition Mac like 6 year driver i...  \n",
            "\n",
            "[73996 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le_model = LabelEncoder()\n",
        "df['Label'] = le_model.fit_transform(df['Label'])"
      ],
      "metadata": {
        "id": "QCTtirkEJu0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['Preprocessed Text'], df['Label'],\n",
        "                                                    test_size=0.2, random_state=42, stratify=df['Label'])"
      ],
      "metadata": {
        "id": "cMVCulG0JyCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u6CamZLJ1AV",
        "outputId": "fcb60d1d-eaa9-4fe4-eb32-dc06b2e94c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train:  (59196,)\n",
            "Shape of X_test:  (14800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create classifier\n",
        "clf = Pipeline([\n",
        "    ('vectorizer_tri_grams', TfidfVectorizer()),\n",
        "    ('naive_bayes', (MultinomialNB()))\n",
        "])"
      ],
      "metadata": {
        "id": "yTUbJhRKJ3nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "PBvRTZ8bJ7EO",
        "outputId": "efd230f9-f569-48f5-fa83-64dfc2088eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer_tri_grams', TfidfVectorizer()),\n",
              "                ('naive_bayes', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer_tri_grams&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;naive_bayes&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer_tri_grams&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;naive_bayes&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get prediction\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "ZDf5zhf7J_2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print score\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oaQYBCTKCQO",
        "outputId": "2ad1975d-71bd-4ebc-e937-26cf106c1ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7312837837837838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAf358SxKEzT",
        "outputId": "3e3f4091-2380-4abc-f3ac-f37a9d81521f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.46      0.62      2575\n",
            "           1       0.65      0.90      0.76      4472\n",
            "           2       0.84      0.63      0.72      3622\n",
            "           3       0.71      0.81      0.76      4131\n",
            "\n",
            "    accuracy                           0.73     14800\n",
            "   macro avg       0.79      0.70      0.71     14800\n",
            "weighted avg       0.77      0.73      0.72     14800\n",
            "\n"
          ]
        }
      ]
    }
  ]
}